<audio id="audio" title="074 | 雅虎：大数据领域的“活雷锋”" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/7f/83/7f45cc410334816f2e95d66791301383.mp3"></audio>

在谷歌崛起之前的很长一段时间里，雅虎一直是互联网行业的“老大哥”。 虽然随着互联网行业的发展，谷歌的市场影响力越来越强，雅虎的日子越来越不好过，但雅虎仍是“瘦死的骆驼比马大”。谷歌发表了“三驾马车”的论文，开启了大数据时代，雅虎作为当时互联网行业的老大，也希望能用上类似“三驾马车”的系统。

鉴于和谷歌在广告市场上的直接竞争关系，雅虎不可能从谷歌那里获得基础架构并用在自己的业务上，而且谷歌也没有要开放自身架构的意思，因此雅虎决定自己开发一套。说到这里，就不得不说说道格 · 卡丁（Doug Cutting）了。

当时，卡丁在做一个叫作Nutch的网页爬虫项目，但是这个项目开发得并不顺利，主要问题是当爬虫达到一定规模后无法稳定地运行在更多的机器上。

这时，谷歌文件系统和MapReduce的论文相继发表了，卡丁从这些论文里面受到了启发。他认为谷歌文件系统和MapReduce可以解决Nutch项目遇到的问题，于是就在Nutch上实施了谷歌文件系统和MapReduce工具，果然重新实现后的Nutch很容易稳定运行在更多的机器上了。

而当时雅虎正在思考如何构建自己的基础架构，于是这个项目自然而然地进入了雅虎的视野。

2006年，雅虎聘用了卡丁，随后专门组建了Hadoop开发团队，并投入了大量的技术人员和机器资源来支持项目的开发、调试和落地。雅虎对Hadoop项目注入的人力和物力资源支持，奠定了Hadoop项目从简陋向完善发展的基础。

Hadoop团队的最高领导者是位副总裁，雅虎很多核心业务部门的最高领导的等级也不过如此，借此不难看出雅虎当时对Hadoop开发部门的重视程度。

不但如此，为了保证Hadoop项目能够顺利落地，雅虎把内部的很多数据处理业务迁移到了尚不成熟的Hadoop项目中。这种用实际业务促进项目成长的“小白鼠”精神，非常有效地帮助了Hadoop向成熟产品的转变。

接下来，我来讲讲Hadoop的具体发展进程。

2006年2月，卡丁决定从Nutch项目里将对谷歌文件系统和MapReduce的实现分离出来，并决定用他儿子的玩具命名这个项目：Hadoop。两个月后，Hadoop实现了第一个具有里程碑意义的计算：用48小时在188台机器上完成了对1.8 TB数据的排序。

这里所说的里程碑，并不是说这件事情有多伟大，而仅仅是证明了基于谷歌文件系统和MapReduce实现的架构，是一个相对通用的系统。这个系统除了可以用在Nutch上做爬虫应用外，还可以实现数据排序。

而这个数据排序的效率到底是高是低呢？现在我用C++随便写一个程序，运行在一台普通电脑上为1.8 TB的数据进行排序，而且这个排序绝对花不了48小时的时间。但是，当时Hadoop却需要用188台机器花费48小时来完成这个排序。

这里需要说明的是，对分布式系统来说，单机效率固然重要，但能够稳定运行在多少台机器上同样重要，而且实现起来更加困难。

到2006年5月，雅虎的Hadoop团队已经有了一个300台机器的集群。同年10月，这个集群达到了600台机器的规模 ，而这基本上接近了当时Hadoop可以实现的极限。整个Hadoop团队又花了差不多大半年的时间，才在2007年上半年实现了Hadoop在1000台机器上的稳定运行。这样的集群规模，终于可以让Hadoop存储和处理互联网级别的数据了。

2008年，Hadoop可以稳定运行了。正是这一年，雅虎决定把自己搜索引擎的倒排索引的构建工作迁移到Hadoop上。因为伴随着互联网内容的增加，在手工实现的系统上构建的倒排索引，再也无法处理越来越多的内容。

谷歌最初发明MapReduce的目的就是为自己的搜索引擎构建倒排索引，所以Hadoop一旦足够稳定，雅虎必然会将自己的倒排索引构建工作迁移到Hadoop上。这个处理雅虎倒排索引构建工作的Hadoop集群，规模大约在2000到3000台机器之间，这也是当时最大的Hadoop集群。

2009年，雅虎的很多业务都开始迁移到Hadoop上。为此，雅虎部署了很多个Hadoop集群，总机器规模超过两万台。

**可以说，2006年到2009年是Hadoop项目发展最为关键的三年。在这三年的时间里，雅虎不但从人力上和机器上给予了Hadoop大量的支持，更重要的是逐渐把自己内部的很多平台都过渡到Hadoop上。** 如果没有雅虎的这些大力支持，也就不会有Hadoop在2009年的成熟程度。

如果说，雅虎为了发展自己的业务在Hadoop项目上投入了如此多的资源，是情理之中的事情，那么雅虎毫无保留地把Hadoop相关的源代码全部开源出来，就必须说是扮演了一个“活雷锋”的角色了。因为雅虎无私地开源了Hadoop系统，其他比如LinkedIn和Facebook等互联网公司才有可能加盟进来。

除了Hadoop的核心系统以外，雅虎对Hadoop生态圈还有两个比较大的贡献：ZooKeeper项目和Pig项目，它们对Hadoop生态圈的发展产生了非常重要的影响。

ZooKeeper是一个分布式系统的协调服务，主要用来解决分布式应用中经常遇到的一些数据管理问题。它是很多Hadoop生态圈的其他项目（比如，谷歌BigTable的大数据开源版HBase）里面分布式协调部分的代码的基础。

Pig是第一个基于Hadoop的高级语言，它的脚本被编译成一系列的MapReduce任务来执行。Pig第一次让用户摆脱了烦琐的MapReduce，可以用高级语言去写任务，这就像是计算机从早期的汇编语言阶段过渡到了高级语言阶段。

现在十年多的时间过去了，Zookeeper作为一个基础组件，不断地演进，至今依然是Hadoop生态圈里最重要的一个基础组件。Pig则渐渐地被后来居上的高级语言，比如Spark和Flink，取代了，就像是COBOL被C、C++、Java等更高级的语言取代一样。

总结来说，如果当初没有雅虎对Hadoop项目的鼎力支持以及无私开源，我们很难想象会有今天如此繁荣昌盛的Hadoop生态圈。尽管雅虎作为一个实体公司已经不存在了，尽管我们也不知道当初雅虎为什么要如此无私地开源Hadoop，但我们都应该感谢它对Hadoop多年如一日的无私奉献。


