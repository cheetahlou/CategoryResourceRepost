<audio id="audio" title="结课 | 终有一天，你将为今天的付出骄傲" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/6f/46/6f79a1684d6e01a56f79d89345d95c46.mp3"></audio>

不知不觉间，又一个40期的机器学习专栏也走到了尾声。在专栏里，我从理解概率的两大流派入手，以每种流派中的各个模型为主线，对统计机器学习和贝叶斯机器学习做了系统的介绍，并从这些模型中梳理出它们之间关系的脉络，帮助你尽可能地从更加宏观的角度来理解模型内部的关联。

## 内容：由博返约求精深

和上一季的“人工智能基础课”相比，这一季专栏的内容聚焦于机器学习一点，力求更加深入地挖掘这个主题。增加深度意味着提升难度，无论是写作的我还是阅读的你，都需要投入更多的时间和精力去理解与消化。

理解事物时，我们都习惯从感性认知入手，可要从感性认知进化为理性思辨，你还是不得不和那些恼人的符号和讨厌的公式打交道。然而这是学习的必经之路：直观而具体的认识虽然容易理解，其适用范围却相当有限，要解决现实问题就必须将认识上升到知识的高度，而知识的价值恰恰就蕴含在复杂的公式所体现出的规律之中。

**具有普适性的抽象规律，才具有学习的价值**。在机器学习中，各种各样的模型某种程度而言其实也是简单具体的实例，诸如局部化和集成化之类的方法才是支配模型演变的规律。正是这些规律与统计学习的理论相结合，才让机器学习变得魅力无穷。

## 收获：见贤思齐多自省

工作上的职责所在让我接触了很多关于教学的文献与范例，其中一些国内外教学名家的课程堪称醍醐灌顶。虽然学科有所区别，但这些大师总能深入浅出、化繁为简，将深奥的道理以老妪能懂的形式清晰而准确地解释出来。体验这些大师的授课是种享受，在艰辛的求索中感受到一丝如沐春风的惬意。

罗马不是一天建成的，大师们的举重若轻也是来源于多年积累的深厚功底。博学多闻才能融会贯通，只有将广博的专业知识和精湛的教学技艺相结合，方能达到这样的境界。在我自己的角度看，从这个专栏得到的最大收获便是一份鞭策，它在不断提醒我对自己的提升依然任重而道远。

## 启示：莫道前路多崎岖

最近几年，所谓的“一万小时”理论声名鹊起，甚至被人奉为圭臬。可是在我看来，它无非说明了一个再简单不过的道理：有付出才有收获。究竟练习了一万小时还是两万小时并不是关键，关键在于填满这时间的努力。如果你天赋异禀外加勤于思考，两千个小时可能就足以成为高手；可要是像学弈时净想着射落天鹅的那个小孩一样，怕是十万个小时也是白搭。

**之所以要花费这么多的努力和时间，是因为没有任何学问是简单的**。如果以玩儿票的态度对待新知，那大可不必为此大费思量；可是要深入学习一门学问的话，这样的痛苦就是必经之路，奢求速成的捷径百分之百徒劳无功。

任何一个成熟的学科都是诸多天才前辈智慧的结晶，如果这些天赋异禀之人尚且需要劈波斩浪，平凡的我辈便只有更加努力，才能在浩瀚的学海中求得生存。只有经过一波又一波惊涛骇浪的洗礼，才有资格去欣赏对岸无双的美景。

不经历风雨，怎能见彩虹，没有人能随随便便成功。终有一天，你将为今天的付出骄傲，加油！

[<img src="https://static001.geekbang.org/resource/image/f6/34/f691d4aa61d15c576d5a2128d6a95134.jpg" alt="" />](http://geektime.mikecrm.com/yweliWa)
