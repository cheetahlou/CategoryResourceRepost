<audio id="audio" title="069 | Hadoop及其发行商的未来" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/2f/d8/2fa1cedf52a73bcbb54d5827dfa5a9d8.mp3"></audio>

Hadoop以及它的生态圈，从开始到现在也已经有差不多十年历史了。Hadoop从雅虎支持的一个开源项目，到由很多项目组成的Hadoop生态圈，以及依靠Hadoop发行版开展商业活动的三大公司Cloudera、Hortonworks以及MapR，其发展不可谓不迅猛。

我在前面重点介绍了Hadoop的三大发行商，希望通过对其历史、技术和商业模式等各方面的介绍，让你对Hadoop当前的商业化状况有了一定的了解。

那么十年之后，整个生态圈又发生了哪些变化，Hadoop发行商们的未来又会是怎样呢？本文就来探讨这方面的问题。

Hadoop诞生的原因有很多，但是最重要的一条是除去谷歌，硅谷的其他互联网公司们每一个单拎出来，其研发能力都有限，不太可能构建出谷歌那样的大数据架构。而互联网业务的发展决定了这一套大数据架构是不可或缺的，所以这些“兄弟们”以雅虎和Facebook为首，开始抱团取暖，在Hadoop这个开源产品下，逐渐构建出了整个生态体系。

因此，这个生态体系最初的服务对象也是这些互联网公司。互联网公司的研发能力都很强，可以自己定制系统，所以Hadoop生态圈的发展，在很长一段时间里都不够稳定。而传统的非IT企业，则不愿意使用Hadoop。

这种情况随着Cloudera、MapR和Hortonworks的加入，有了很大的改善。这些Hadoop发行商提供的版本，不但是Hadoop的稳定版本，而且加入了很多帮助传统企业使用Hadoop的工具。这些厂商成了Hadoop生态圈里的另外一批受益者。

**但是它们都算不上Hadoop生态圈里最大的受益者，从实际情况来看，亚马逊这个全球最大的云计算厂商才是**。这里面有两方面原因。

首先，亚马逊自己的研发能力也不足以开发出一套大数据分析生态系统，但是它同样需要类似Hadoop的大数据分析平台，所以亚马逊内部就需要使用Hadoop。这样一来，亚马逊就需要研究怎么在自己内部部署Hadoop系统。

其次，亚马逊又是全球最大的云计算厂商，其所有云计算服务对内对外的接口完全一样，因此通过在亚马逊实现Hadoop的自动运行，除了服务亚马逊，更可以提供服务给外部使用，这就是Elastic MapReduce服务。这不仅让各大企业省去了购买机器集群和管理机器集群的负担，而且让亚马逊卖出了更多的云服务。这种“一鱼两吃”的做法，让亚马逊迅速做大了自己的圈子。

与之相反，其他两个云厂商——微软和谷歌，一开始都不是Hadoop生态圈的，它们都研发了自己的大数据处理平台，供内部使用，因此对于让Hadoop在云端运行起来没有那么大兴趣。等到它们发现，原来亚马逊已经靠云卖Hadoop赚了很多钱，多少有些为时已晚。

**亚马逊的Hadoop云端服务，同时摊薄了谷歌和微软这样的云厂商，以及Cloudera、MapR和Hortonworks这些Hadoop发行商的盈利空间。**

Cloudera意识到了亚马逊模式的威胁，在2016年曾经试图和英特尔沟通，让其投资Cloudera做云上的Hadoop服务，以便和亚马逊竞争。

然而，可能英特尔同时也是亚马逊的大主顾，亚马逊数据中心需要大量采购英特尔的硬件，又或者是英特尔自己并不想全面进入云计算这个领域，总之Cloudera没有获得足够的资金，这个计划就搁浅了。之后因为盈利不佳，融资不易，它只能自砍估值一半，流血上市。

**在这次战争里，亚马逊笑到了最后，还有另外一个原因。亚马逊推出来的存储服务S3历史悠久，非常稳定，而Hadoop本身的文件系统HDFS则比较糟糕、效率很低**。在亚马逊实现Elastic MapReduce的时候，对文件系统的处理，并非是基于HDFS的，而是把自己的S3作为存储系统，在上面实现了HDFS的接口而已。

面对一个非常稳定的文件系统，有无数的大小企业又都把自己的数据存在这个文件系统上，Elastic MapReduce相比原生Hadoop系统表现出了更高的效率、更好的性能，自然更受欢迎。加上亚马逊出了名的控制成本、定价便宜，其他Hadoop厂商要想在亚马逊的进攻下赚到钱，就比较艰难了。

微软的转型相对快一些。HDInsight就是微软的Hadoop云产品。它的文件系统也不再是简单的复用HDFS，而是在Windows Azure的存储上实现了HDFS的接口而已。

经过十年的发展，Hadoop所有在云上的版本，基本上都只是实现了HDFS的接口，却不用HDFS的完整实现，这是目前很多人觉得HDFS已死的原因。

另外，Hadoop早年实现的数据处理框架MapReduce，如今在整个生态圈里也被DataBricks主导的Spark打败，Spark已经成为通行的标准了。从这个角度来看，当年雅虎推出的那个Hadoop，经过这么多年的演变，很多东西都已经空心化，被新的技术取代了，留下来的只是接口。

**数据处理框架的影响，从目前来看，比文件系统演变的影响要小**。有一点很重要，就是亚马逊的Elastic MapReduce虽然取了这个名字，但其服务其实是提供了一个虚拟的Hadoop集群。既然是Hadoop集群，那么不跑MapReduce，而是跑Spark本身也不是问题。所以说名字可以欺骗人，但是数据处理框架的改变，一点都不影响亚马逊赚钱。

**Hadoop三大发行商的空间，这些年里越来越被云厂商提供的Hadoop服务给占领了，所以它们的日子都不太好过。现在云厂商占领不了的那些，更多是不想上云，或者还没上云的传统企业**。这些企业基于各种考虑，或者是数据安全的问题，或者是自身的IT能力比较弱，所以会选择三大发型商之一的版本。

在这三个版本里，HDFS被重写的MapR版本其文件系统相对稳定，性能更好；而其他两家的版本则基于老的HDFS。整体上看，MapR的版本在存储层可以提供更多的企业级特性，但是要确保和Hadoop生态圈的其他产品兼容却不太容易；Cloudera家大业大，目前可能拥有了最优质的线下客户资源；而Hortonworks暂时看不到任何优势。

在我看来，企业上云是必然趋势。但Cloudera和MapR需要新的盈利增长点，才能抵消企业上云带来的损失，否则长久来看，还是会逐渐走下坡路。而Hortonworks从技术和非技术的各方面表现来看，与竞争对手的差距很遥远，恐怕不出时日，日子就会不好过了。


