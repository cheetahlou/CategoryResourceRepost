<audio id="audio" title="开篇词 | 打通修炼机器学习的任督二脉" controls="" preload="none"><source id="mp3" src="https://static001.geekbang.org/resource/audio/57/96/57db17eacd05aef84567ab8e07335796.mp3"></audio>

你好，我是王天一，我在“机器学习40讲”欢迎你的到来！

在上一季的专栏中，我与你一起走马观花地浏览了学习人工智能所需要的基础数学、当前流行的深度学习、以及其他可能实现智能的技术路径。广义的人工智能概念可以说包罗万象，其中每一个细分的子领域发展到今天都值得大书特书。40篇文章的篇幅绘出的人工智能轮廓就像是一幅低分辨率的全景画，覆盖广度的同时必然难以兼顾深度。

正因如此，新一季的专栏内容将聚焦于人工智能大问题里的一个小目标——**机器学习**。在新进展层出不穷的今日，机器学习依然占据着人工智能的核心地位，迅猛的发展势头也让现在的机器学习领域充斥着各种听起来狂拽酷炫的新玩意儿。但阳光之下再无新事，**再炫目的技术归根结底都是基本模型与方法在具体领域问题上的组合，而理解这些基本模型与方法才是掌握机器学习，也是掌握任何一门学问的要义所在**。

既然机器学习领域的文献论著已经汗牛充栋，这个专栏和它们的区别又在哪里呢？在我看来，是**融会贯通的系统性**。不少关于机器学习的文献虽然深入阐释了不同模型的原理，但对它们之间的关联却缺少清晰的解释，从而使内容的组织流于模型展览，仿佛一串没能串成项链的珍珠宝石。实际上，所有模型就像龙生九子一样，都是从基本模型出发，根据不同改进方法衍生出来。所以，这个专栏最重要的任务就是**帮助你把握不同模型之间的内在关联，让你形成观察机器学习的宏观视角，找准进一步理解与创新的方向**。

在内容上，“机器学习”分为3个模块。

第一个模块是**机器学习概观**，介绍机器学习中超脱于具体模型和方法之上的一些共性问题，将从概率的两大派别开始。众所周知，概率在机器学习中扮演着核心角色，而频率学派与贝叶斯学派对概率迥异的认知也将机器学习一分为二，发展出两套完全不同的理论体系。正所谓兼听则明偏听则暗，理解机器学习时应该看到这同一枚硬币的两面，以获得完整的认知。除此之外，本模块还涵盖了计算学习等机器学习的理论问题，以及关于模型和特征的一些实验主题。

第二个模块将讨论频率学派发展出的机器学习理论——统计学习。**统计机器学习**的核心是数据，它既从数据中来，利用不同的模型去拟合数据背后的规律；也到数据中去，用拟合出的规律去推断和预测未知的结果。统计学习中最基础的模型是线性回归，几乎所有其他模型都是从不同角度对线性回归模型做出的扩展与修正。因此，在这个模块中，我将以**线性模型**为主线，和你一起浏览它的万千变化，观察从简单线性回归到复杂深度网络的发展历程。

第三个模块将讨论贝叶斯学派发展出的机器学习理论——符号学习，也就是**概率图模型**。和基于数据的统计学习相比，基于关系的图模型更多地代表了因果推理的发展方向。贝叶斯主义也需要计算待学习对象的概率分布，但它利用的不是海量的具体数据，而是变量之间的相关关系、每个变量的先验分布和大量复杂的积分技巧。在这个模块中，我将围绕概率图模型中的**表示、推断、学习**三大问题展开介绍，认识贝叶斯面纱下的机器学习。

除了理论之外，在介绍模型时我还会穿插一些**基于Python语言的简单实例**以加强理解。这些实例会应用诸如Scikit-Learn和PyMC等比较成熟的第三方库，通过调用现成的类来实现不同模型的功能。Python语言的一大优势就是功能丰富又强大的第三方库，将它们束之高阁未免暴殄天物。在快速实现的基础上再进一步深入钻研核心代码，也是比较合理的学习路径。

理解机器学习绝不是简单地了解几个时髦概念，而是要将前沿和基础融会贯通，从中发现贯穿学科发展的脉络。这个专栏不是乾坤大挪移这种水平的内功心法，但如果能**打通你修炼机器学习的任督二脉**，它的价值就实现了。

我已做好准备，在接下来的三个多月里，和你分享我所理解的机器学习。也请你告诉我，你为什么要学习机器学习？你希望通过这个专栏得到哪些收获呢？

与君共勉！

<img src="https://static001.geekbang.org/resource/image/d6/a2/d659043286059985903c7c1151e66da2.jpg" alt="" />
